{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1663690276887,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"Y48HukVGD54z","outputId":"d955ee63-c044-4e01-dd2d-35ac367a78cc"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663690277234,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"H8NB6bVLD548"},"outputs":[],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3332,"status":"ok","timestamp":1663690280564,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"KNgWM7TID55A","outputId":"da72b3c2-c93f-4db4-a368-1cadd31c2434"},"outputs":[],"source":["# load folder\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1663690280564,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"WX5X9d_9D55F"},"outputs":[],"source":["# please change the path of your dataset here below\n","ROOT_PATH = \"/content/drive/MyDrive/colab notebook/data_exp/german_med_termss/\"\n","# ROOT_PATH= \"updated_german_med_terms/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146004,"status":"ok","timestamp":1663690426565,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"ol1_d3YGD55I","outputId":"faf9085b-5d10-4200-e6b8-29e1a278098a"},"outputs":[],"source":["# install all needed libraries\n","!pip install transformers\n","!pip install pytorch-lightning\n","!pip install transformers datasets --quiet\n","!pip install -U imbalanced-learn\n","!pip install scikit-multilearn\n","\n","!pip install spacy\n","!pip install spacy-transformers\n","!python3 -m spacy download de_dep_news_trf\n","!python3 -m spacy download de_core_news_lg\n","\n","# !python -m spacy download de_dep_news_trf"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1663690426566,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"_YXygSwCD55M"},"outputs":[],"source":["import torch\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","from transformers import BertTokenizerFast, BertForSequenceClassification, BertTokenizer, BertForMultipleChoice\n","from transformers import Trainer, TrainingArguments\n","import numpy as np\n","import random\n","from sklearn.model_selection import train_test_split\n","import os\n","import pandas as pd\n","import ast\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder\n","from imblearn.under_sampling import RandomUnderSampler\n","import datasets\n","from datasets import Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17299,"status":"ok","timestamp":1663690443860,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"OuQW3Y_VD55P","outputId":"1cfc61cf-e085-40cd-a462-df161b58108f"},"outputs":[],"source":["files = os.listdir(ROOT_PATH)\n","filepaths = [ROOT_PATH + f for f in os.listdir(ROOT_PATH) if f.endswith('.csv')]\n","df = pd.concat(map(pd.read_csv, filepaths))\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1495,"status":"ok","timestamp":1663690445350,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"ZOipfAZsD55T","outputId":"89ff51cf-9e4a-4871-c344-8a2c883a5fb9"},"outputs":[],"source":["def tx(x):\n","  res = []\n","  for v in ast.literal_eval(x):\n","    res.append(str(v).strip().lower())\n","  return res\n","\n","\n","df['labels_array']= df['expertise'].apply(lambda x: tx(x))\n","df = df[pd.notna(df['labels_array'])]\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1663690445350,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"pixkQnRIb_Ih","outputId":"ced4e120-f869-4030-bec8-e90f6d7f3770"},"outputs":[],"source":["def get_categories_with_index(labels_classfified: dict):\n","    categories = []\n","    main = labels_classfified['Unnamed: 1']\n","    for k,v in main.items():\n","        if type(v) == str:\n","            categories.append(v)\n","    \n","    categories_with_index = []\n","    for i in range(len(categories) -1 ):\n","        start = list(main.values()).index(str(categories[i]))\n","        end = list(main.values()).index(str(categories[i + 1])) - 1\n","\n","        main_category = str(categories[i]).lower()\n","        categories_with_index.append({\"category\": categories[i], \"start\": start, \"end\": end, \"values\": [main_category]})\n","    \n","    # for the last category\n","    last_category = categories[-1].lower()\n","    categories_with_index.append({\"category\": last_category, \"start\": -1, \"end\": -1, \"values\": [last_category]})\n","    \n","    columns = list(labels_classfified.keys())[2:]\n","    for v in columns:\n","        for ci in categories_with_index:\n","            ci['category'] = str(ci['category']).lower()\n","            ci['values'] += found(labels_classfified[v], ci)\n","        \n","    return categories_with_index\n","\n","def found(dict_under, ci):\n","    values = []\n","    for k,v in dict_under.items():\n","        if k > ci['start'] and k < ci['end'] and type(v) == str:\n","            values += [str(v).lower()]\n","    \n","    return list(set(values))\n","\n","categories_with_index = get_categories_with_index(pd.read_excel('../content/drive/MyDrive/colab notebook/Praxisprojekt_MMC.xlsx').to_dict())\n","# categories_with_index = get_categories_with_index(pd.read_excel('Praxisprojekt_MMC.xlsx').to_dict())\n","target_names = [c['category'] for c in categories_with_index]\n","print(target_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1663690445350,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"F9Fc7lbkb_Ij"},"outputs":[],"source":["def change_label_to_main_category(x):\n","    result = []\n","    for value_from_x in x:\n","        for ci in categories_with_index:\n","            if value_from_x in ci['values']:\n","                result.append(ci['category'])\n","\n","    return list(set(result))\n","\n","df['labels_array']= df['labels_array'].apply(lambda x: change_label_to_main_category(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1663690445693,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"m1rIfpEhb_Ik","outputId":"7896a83d-5159-4b0a-9f0e-4a5f8ddda30d"},"outputs":[],"source":["print(df['labels_array'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2709,"status":"ok","timestamp":1663690448396,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"rl4Mgniqb_Il","outputId":"9a019030-ee05-4444-8680-a1755bda99fd"},"outputs":[],"source":["\n","def get_number_of_sample_per_label(df, number_of_sample_per_label):\n","    result = []\n","\n","    for label, count in df['labels_array'].value_counts().items():\n","        if count <= number_of_sample_per_label:\n","            result += [label]\n","\n","    print(\"count -> \", len(result))\n","    return result\n","\n","found_labels = get_number_of_sample_per_label(df, 1)\n","print(found_labels)\n","\n","if len(found_labels) > 0:\n","    ri = []\n","    for index, row in df.iterrows():\n","        for l in found_labels:\n","            if l == row['labels_array']:\n","                ri.append(index)\n","\n","    print(\"ri\", ri)\n","    df.drop(index=ri, inplace = True)\n","    df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1663690448396,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"K_vC4dxhb_Im","outputId":"4a375910-a2a0-4935-9f42-587b5d66a17a"},"outputs":[],"source":["print(df['labels_array'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":344,"status":"ok","timestamp":1663690448735,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"v6XaNbESb_Im","outputId":"0436bf89-71c9-4011-fe50-b6468b5d8cc4"},"outputs":[],"source":["df_train, df_val = train_test_split(df, test_size=0.2, random_state=42, stratify=df['labels_array'])\n","print(df_train.shape, df_val.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663690448736,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"Q_RCPngWb_In"},"outputs":[],"source":["def explode_doc(df):\n","    df['doc'] = df[['all_page', 'wiki_content']].apply(lambda x: [str(x['all_page']) ]+ [str(x['wiki_content']) ], axis=1)\n","    df = df.explode(\"doc\")\n","\n","    df = df[pd.notna(df['doc'])]\n","    df['doc'] = df['doc'].replace('nan', np.nan)\n","    df.dropna(subset=['doc'], inplace=True)  \n","\n","    return df\n","\n","def explode_labels_array(df):\n","\n","    df = df.explode(\"labels_array\")\n","    df.rename(columns = {'labels_array': 'label'}, inplace = True)\n","\n","    df['label'].replace('', np.nan, inplace=True)\n","    df.dropna(subset=['label'], inplace=True) \n","\n","    sns.set(rc={'figure.figsize':(11.7,8.27)})\n","    sns.countplot(data=df, y=\"label\", orient=\"v\")\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11592,"status":"ok","timestamp":1663690460325,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"X-ckGQTQD55m"},"outputs":[],"source":["import re\n","from typing import List\n","\n","import spacy\n","from spacy.tokens import Doc\n","from tqdm import tqdm\n","\n","\n","class SpacyPreprocessor:\n","    def __init__(\n","        self,\n","        spacy_model=None,\n","        remove_numbers=False,\n","        remove_special=True,\n","        pos_to_remove=None,\n","        remove_stopwords=False,\n","        lemmatize=False,\n","        remove_duplicates=False,\n","        extra_abbreviations=[]\n","    ):\n","        \"\"\"\n","        Preprocesses text using spaCy\n","        :param remove_numbers: Whether to remove numbers from text\n","        :param remove_stopwords: Whether to remove stopwords from text\n","        :param remove_special: Whether to remove special characters (including numbers)\n","        :param pos_to_remove: list of PoS tags to remove\n","        :param lemmatize:  Whether to apply lemmatization\n","        \"\"\"\n","\n","        self._remove_numbers = remove_numbers\n","        self._pos_to_remove = pos_to_remove\n","        self._remove_stopwords = remove_stopwords\n","        self._remove_special = remove_special\n","        self._lemmatize = lemmatize\n","        self.remove_duplicates = remove_duplicates\n","        self.extra_abbreviations = extra_abbreviations\n","\n","        if not spacy_model:\n","            self.model = spacy.load(\"de_core_news_lg\")\n","        else:\n","            self.model = spacy_model\n","\n","    @staticmethod\n","    def download_spacy_model(model=\"de_core_news_lg\"):\n","        print(f\"Downloading spaCy model {model}\")\n","        spacy.cli.download(model)\n","        print(f\"Finished downloading model\")\n","\n","    @staticmethod\n","    def load_model(model=\"de_core_news_lg\"):\n","        return spacy.load(model, disable=[\"ner\", \"parser\"])\n","\n","    def tokenize(self, text) -> List[str]:\n","        \"\"\"\n","        Tokenize text using a spaCy pipeline\n","        :param text: Text to tokenize\n","        :return: list of str\n","        \"\"\"\n","        doc = self.model(text)\n","        return [token.text for token in doc]\n","\n","    def preprocess_text(self, text) -> str:\n","        \"\"\"\n","        Runs a spaCy pipeline and removes unwanted parts from text\n","        :param text: text string to clean\n","        :return: str, clean text\n","        \"\"\"\n","\n","        if self.extra_abbreviations == []:\n","            adds = self.extra_abbreviations\n","            for add in adds:\n","                text = text.replace(add, \"\")\n","\n","        doc = self.model(text)\n","        return self.__clean(doc)\n","\n","    def preprocess_text_list(self, texts=List[str]) -> List[str]:\n","        \"\"\"\n","        Runs a spaCy pipeline and removes unwantes parts from a list of text.\n","        Leverages spaCy's `pipe` for faster batch processing.\n","        :param texts: List of texts to clean\n","        :return: List of clean texts\n","        \"\"\"\n","        clean_texts = []\n","        for doc in tqdm(self.model.pipe(texts)):\n","            clean_texts.append(self.__clean(doc))\n","\n","        return clean_texts\n","\n","    def __clean(self, doc: Doc) -> str:\n","    \n","        tokens = []\n","        # POS Tags removal\n","        if self._pos_to_remove:\n","            for token in doc:\n","                if token.pos_ not in self._pos_to_remove:\n","                    tokens.append(token)\n","        else:\n","            tokens = doc\n","\n","        # Remove Numbers\n","        if self._remove_numbers:\n","            tokens = [\n","                token for token in tokens if not (token.like_num or token.is_currency)\n","            ]\n","        \n","\n","        # Remove Stopwords\n","        if self._remove_stopwords:\n","            tokens = [token for token in tokens if not token.is_stop]\n","        \n","            \n","        # remove unwanted tokens\n","        tokens = [\n","            token\n","            for token in tokens\n","            if not (\n","                token.is_punct or token.is_space or token.is_quote or token.is_bracket\n","            )\n","        ]\n","\n","        # Remove empty tokens\n","        tokens = [token for token in tokens if token.text.strip() != \"\"]\n","\n","        # # Remove duplicates\n","        # if self.remove_duplicates:\n","        #     tokens = list(set(tokens))\n","\n","        # Lemmatize\n","        if self._lemmatize:\n","            # text = \" \".join([token.lemma_ for token in tokens])\n","            words = [token.lemma_ for token in tokens]\n","        else:\n","            # text = \" \".join([token.text for token in tokens])\n","            words = [token.text for token in tokens]\n","        \n","        if self._remove_special:\n","            words = [re.sub(r\"[^a-zA-Z0-9äöüÄÖÜß]\", \" \", str(word)) for word in words]\n","            # words = [re.sub(r\"[^\\x00-\\x7F]+\", \"\", word) for word in words]\n","            words = [word for word in words if len(word.strip()) > 0 ]\n","\n","        # if self._remove_special:\n","        #     # Remove non alphabetic characters\n","        #     text = re.sub(r\"[^a-zA-Z\\']\", \" \", text)\n","        # # remove non-Unicode characters\n","        # text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n","\n","        # text = text.lower()\n","\n","        return words # \" \".join(words)\n","\n","\n","spacy_model = SpacyPreprocessor.load_model()\n","preprocessor = SpacyPreprocessor(spacy_model=spacy_model, lemmatize=True, remove_numbers=False, remove_stopwords=True, remove_special=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3958,"status":"ok","timestamp":1663690464279,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"2klMqZ78D55s","outputId":"b2231819-e416-40a6-b0f9-f1d918393a41"},"outputs":[],"source":["# print(\"---------------------------LABELS ARRAYS--------------------------------\")\n","# print(df_train['labels_array'].value_counts())\n","# print(\"-----------------------------------------------------------------\")\n","# print(df_val['labels_array'].value_counts())\n","\n","\n","df_train = explode_doc(df_train)\n","df_val = explode_doc(df_val)\n","\n","print(df_train.shape)\n","print(df_val.shape)\n","\n","# print(\"---------------------------LABELS--------------------------------\")\n","# print(df_train['label'].value_counts())\n","# print(\"-----------------------------------------------------------------\")\n","# print(df_val['label'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1663690464280,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"oAKXKlZkb_Ip"},"outputs":[],"source":["###################################################################\n","# df_train = df_train.head(200)\n","# df_val = df_val.head(3)\n","####################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1663690464280,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"bZLLtRazD55t","outputId":"a708d90f-d328-436b-f623-fea1f08fcfb6"},"outputs":[],"source":["train_documents = df_train['doc']\n","train_categories = df_train['labels_array']\n","test_documents = df_val['doc']\n","test_categories = df_val['labels_array']\n","\n","print(train_documents.shape, train_categories.shape)\n","print(test_documents.shape, test_categories.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4796405,"status":"ok","timestamp":1663695260662,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"j0O0-oEaD55v"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import HashingVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","vectorizer = TfidfVectorizer(\n","        tokenizer = preprocessor.preprocess_text, \n","        analyzer = 'word', \n","        lowercase=False, \n","        use_idf=True,\n","        # max_features=512\n","    )\n","\n","vectorised_train_documents = vectorizer.fit_transform(train_documents)\n","vectorised_test_documents = vectorizer.transform(test_documents)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1663695260663,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"qj7RzxLwD55w"},"outputs":[],"source":["train_labels = train_categories\n","test_labels = test_categories"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663695260663,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"JZ8OGdLdD55y"},"outputs":[],"source":["from sklearn.preprocessing import MultiLabelBinarizer\n","\n","label_encoder = MultiLabelBinarizer()\n","train_labels = label_encoder.fit_transform(train_categories)\n","test_labels = label_encoder.transform(test_categories)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265954,"status":"ok","timestamp":1663695526614,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"},"user_tz":-120},"id":"ZlbfH2NRD550","outputId":"2ae6a393-e83a-45cc-8c14-b1adddd85640"},"outputs":[],"source":["from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","model = LogisticRegression(multi_class='ovr', random_state=2, n_jobs=-1)\n","classifier = OneVsRestClassifier(model)\n","classifier.fit(vectorised_train_documents, train_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5dJs5CHD551"},"outputs":[],"source":["from sklearn.model_selection import KFold, cross_val_score\n","\n","kf = KFold(n_splits=10, random_state = 42, shuffle = True)\n","scores = cross_val_score(classifier, vectorised_train_documents, train_labels, cv = kf)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rcpmho5uD552"},"outputs":[],"source":["print('Cross-validation scores:', scores)\n","print('Cross-validation accuracy: {:.4f} (+/- {:.4f})'.format(scores.mean(), scores.std() * 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vu9Pp1yuD553"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","\n","predictions = classifier.predict(vectorised_test_documents)\n","\n","accuracy = accuracy_score(test_labels, predictions)\n","\n","macro_precision = precision_score(test_labels, predictions, average='macro')\n","macro_recall = recall_score(test_labels, predictions, average='macro')\n","macro_f1 = f1_score(test_labels, predictions, average='macro')\n","\n","micro_precision = precision_score(test_labels, predictions, average='micro')\n","micro_recall = recall_score(test_labels, predictions, average='micro')\n","micro_f1 = f1_score(test_labels, predictions, average='micro')\n","\n","cm =  confusion_matrix(test_labels.argmax(axis = 1), predictions.argmax(axis = 1))\n","cr = classification_report(test_labels.argmax(axis = 1), predictions.argmax(axis = 1)) #, target_names = target_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-K7emZQVD554"},"outputs":[],"source":["print(\"Accuracy: {:.4f}\\nPrecision:\\n- Macro: {:.4f}\\n- Micro: {:.4f}\\nRecall:\\n- Macro: {:.4f}\\n- Micro: {:.4f}\\nF1-measure:\\n- Macro: {:.4f}\\n- Micro: {:.4f}\".format(accuracy, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gdmadji1D555"},"outputs":[],"source":["print(cr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKTblkUYD556"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sb\n","import pandas as pd\n","\n","cm_plt = pd.DataFrame(cm[:73])\n","\n","plt.figure(figsize = (25, 25))\n","ax = plt.axes()\n","\n","sb.heatmap(cm_plt, annot=True)\n","\n","ax.xaxis.set_ticks_position('top')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xUXR6oP4b_Iy"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HRQZeB-bD558"},"outputs":[],"source":["def get_input_prediction(input: str):\n","    new_predictions = classifier.predict(vectorizer.transform([input]))\n","    return label_encoder.inverse_transform(new_predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBlyjRwMD559"},"outputs":[],"source":["input = \"\"\"Die Gerontologie reflektiert den Wandel des Altersbildes in der Gesellschaft. Zielgruppe sind hierbei die allgemeine Öffentlichkeit, die Senioren selbst, beruflich mit Senioren befasste Gruppen und die Politik. Als Medium zwischen Universitäten und Allgemeinheit dienen Seniorentage und Kongresse. Zur gerontologischen Forschung zählen die Untersuchung der biologischen Grundlagen des Älterwerdens ebenso wie die Veränderung der sozialen Systeme. Sozialwissenschaften und Demographie bilden Nachbarwissenschaften der Gerontologie. Ziel der Gerontologie ist die Verknüpfung unterschiedlicher Fachbereiche wie Geriatrie, Gerontopsychiatrie, Altenpflege und Sozialarbeit zu einer eigenständigen wissenschaftlichen Disziplin. Es ist eine verstärkte Zuwendung zu pragmatischen Fragestellungen zu beobachten. Auch Disziplinen der Volkswirtschaftslehre bedienen etwa die Frage nach einer optimalen Ausgestaltung des Rentensystems. Wirtschaftswissenschaftliche Kenntnisse werden aufgrund der steigenden Managementorientierung des Bereiches in Zukunft zunehmen. Die Deutsche Bundesregierung hat bislang sieben Altenberichte veröffentlicht, welche die Situation alter Menschen untersuchen (1991 – 2016). \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SGidT4BwD559"},"outputs":[],"source":["####  test ###\n","get_input_prediction(input)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4sq5fkjoD559"},"outputs":[],"source":["le_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n","print(le_name_mapping)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"0081987c862ade64fa8a6b449df670cc6c329610deb4a00a30d291630fdc88f2"}}},"nbformat":4,"nbformat_minor":0}
